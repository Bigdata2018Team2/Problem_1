package common;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import scala.Tuple2;

import java.util.ArrayList;
import java.util.Comparator;

public class APP {
    public static void main(String[] args) {
        SparkConf conf = new SparkConf();
        conf.setAppName("Pair Matching");

        JavaSparkContext jsc = new JavaSparkContext(conf);

        JavaRDD<String> data = jsc.textFile(args[0]);
        double THRESHOLD = Double.parseDouble(args[1]);

        JavaPairRDD<String, String> pairs = data.mapToPair(l -> {
            String[] f = l.split("\t");
            return new Tuple2<>(f[0], f[1]);
        });
        JavaPairRDD<String, String> dPairs = pairs.flatMapToPair(g -> {
            ArrayList<Tuple2<String, String>> result = new ArrayList<>();

            result.add(new Tuple2<>(g._1(), g._2()));
            result.add(new Tuple2<>(g._2(), g._1()));

            return result.iterator();
        });


        JavaPairRDD<String, ArrayList<String>> table = dPairs.groupByKey().mapToPair(g -> {
            ArrayList<String> friends = new ArrayList<>();
            for (String f : g._2())
                friends.add(f);
            return new Tuple2<>(g._1(), friends);
        });

        JavaPairRDD<String, ArrayList<Tuple2<String, Integer>>> invertedTable = table.flatMapToPair(c -> {
            ArrayList<Tuple2<String, Tuple2<String, Integer>>> result = new ArrayList<>();
            String id = c._1();
            ArrayList<String> fs = c._2();
            int fCount = fs.size();

            for (String f : fs) {
                Tuple2<String, Integer> val = new Tuple2<>(id, fCount);
                result.add(new Tuple2<>(f, val));
            }
            return result.iterator();
        }).groupByKey().mapToPair(item -> {
            ArrayList<Tuple2<String, Integer>> fs = new ArrayList<>();
            for (Tuple2<String, Integer> f : item._2())
                fs.add(f);
            return new Tuple2<>(item._1(), fs);
        });

        // Map
        JavaPairRDD<Tuple2<Tuple2<String, Integer>, Tuple2<String, Integer>>, Integer> allCandidate = invertedTable.flatMapToPair(p -> {
            ArrayList<Tuple2<Tuple2<Tuple2<String, Integer>, Tuple2<String, Integer>>, Integer>> result = new ArrayList<>();
            int size = p._2().size();
            for (int i = 0; i < size - 1; ++i) {
                for (int j = i + 1; j < size; ++j) {
                    Tuple2<String, Integer> key1 = new Tuple2<>(p._2().get(i)._1(), p._2().get(i)._2());
                    Tuple2<String, Integer> key2 = new Tuple2<>(p._2().get(j)._1(), p._2().get(i)._2());
                    result.add(new Tuple2<>(new Tuple2<>(key1, key2), 1));
                }
            }
            return result.iterator();
        });

        // Reduce
        JavaPairRDD<Tuple2<Tuple2<String, Integer>, Tuple2<String, Integer>>, Integer> overlapCount = allCandidate.reduceByKey((a, b) -> a + b);
        JavaPairRDD<String, String> overlap = overlapCount.filter(g -> {
            int countA = g._1()._1()._2(), countB = g._1()._2()._2();
            return g._2() >= THRESHOLD / ((1 + THRESHOLD) * (countA + countB));
        }).mapToPair(g -> new Tuple2<>(g._1()._1()._1(), g._1()._2()._1())).subtractByKey(pairs);
        JavaPairRDD<String, String> sortedOverlap = overlap.sortByKey();

        for (Tuple2<String, String> candidate : sortedOverlap.collect()) {
            System.out.println(candidate._1() + " " + candidate._2());
        }
    }
}
